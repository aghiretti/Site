---
title: "Media Mix Modeling via Dynamic Linear Regression"
description: | 
  In this post we discuss the application of the Dynamic Linear Regression 
  model to Media Mix Modeling. To fit the model we will use the R package MARSS.
categories:
  - Econometrics
  - R
  - Time Series
  - Marketing
preview: Preview.jpg
author:
  - name: Alessandro Ghiretti
    url: 
date: 08-12-2020
output: 
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 3
bibliography: references.bib
nocite: | 
  @durbin2012time, @harvey1989time, @dlmharvey, @MARSS, @chan2017challenges, 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

Marketers are generally interested in building models that link different marketing 
variables such as sales activities, operations and external factors, to changes in consumer behavior, 
such as acquisition, sales, revenue, and retention. Once the model are implemented 
these can then support the development of forwardlooking business simulations and optimization exercises. 
When only advertising variables are included in the model this practice is generally called **media mix modeling**.

One of the models most used in practice for media mix modeling is the linear 
regression model. Once the regression is fitted and unknown parameters are estimated, 
it is possible to infer the marginal effect that the different explanatory variables have 
on the response variable. One limitation of the plain linear regression model is that 
the estimates of the parameters remain constant over time. This assumption might be limited in some context,
for example in marketing, where it is well known that the preferences of the customers 
or the penetration of a certain media evolves with time.

In order to overcome this limitation the Dynamic Linear Regression Model (DLM), which allows for 
time varying parameters represent a powerful alternative to plain linear regression. 
Once the DLM is formulated in State Space form it is possible to estimate the 
parameters in a dynamic way and conduct a series of inferential procedures.



# Dynamic Linear Model
Given a standard linear regression model

$$
y_{t} = x'_{t} \beta + \epsilon_{t} \quad \epsilon_{t} \sim N(0, \sigma^{2}) 
$$

where $y_{i}$ is a scalar variable, $x_{i}$ is a $ k \times 1$ vector of 
regressors, $\beta$ is a $k \times 1$ vector of unknown parameters
and $\epsilon_{i}$ is a disturbance term, a dynamic linear model is obtained by
allowing the paramters $\beta$ to evolve over time thorough a prescribed stochastic
model. That is,

$$
\begin{aligned}
y_{t} & = x'_{t} \beta_{t} + \epsilon_{t} \quad  & \epsilon_{t} \sim N(0,\sigma^{2})\\
\beta_{t}& = f(\beta_{t-1}) + v_{t} \quad  & v_{t} \sim N(0,R)
\end{aligned}
$$
Several specifications of $f(\cdot)$ can be specified but here we will consider the cases where $f(\cdot)$ is a linear function. 
A Dynamic Linear Regression (DLR) model therefore is a linear regression model where the parameters
are allowed to change over time according to a specific stochastic process.
A natural and useful representation of the DLM can be obtained by casting the model in state space form,
which represent a general representation for many other statistical models.
In its most general form a state space model is defined by the following two equations

$$
\begin{aligned}
x_{t} & =B_{t} x_{t-1}+ u_{t}+ C_{t} c_{t}+ G_{t} w_{t}, & \quad w_{t} \sim MVN\left(0, Q_{t}\right) \\
y_{t} & =Z_{t} x_{t}+a_{t}+D_{t} d_{t}+H_{t} v_{t}, & \quad v_{t} \sim MVN\left(0, R_{t}\right) \\

\end{aligned}
$$

where $x_{1} \sim MVN(\pi, \Lambda)$ or $x_{0} \sim MVN(\pi, \Lambda)$.
Here $y_{t}$ and $x_{t}$ can be multivariate series and the index $t$ denotes that the matrix are allowed to change over time. The different matrices are in generally not know and are related to a series of unknown parameters that need to be estimated. Estimation of the unknown parameters and the related quantities necessary for inference are obtained by running the Kalman Filter see @durbin2012time or @harvey1989time for a detailed description. 
Following the state space specification the dynamic linear regression model can
be easily represented. The unknown parameters $\beta$ corresponds to the state of the system
and the smoothed states obtained with the Kalman Filter represent estimates of
the parameters conditioned on all of the observed data. 
The two most simple dynamic linear models are obtained when a random walk process or an autorgressive process are respectviely adopted adopted to describe the evolution of $\beta_{t}$.



 
In this case each $\beta_{t}$ is assumed to be non stationary and it is modeled
as a random walk. That is,
 

\begin{aligned}

y_{t} & = 

\underbrace{\begin{pmatrix}
1 & x_{1} & \cdots & x_{k}
\end{pmatrix}_{t}}_{B_{t}}

\underbrace{
\begin{pmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{k+1}
\end{pmatrix}_{t}}_{x_{t}}

+ w_{t}

\\

\underbrace{\begin{pmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{k+1}
\end{pmatrix}_{t}}_{x_{t}}


& = 

\underbrace{\begin{pmatrix}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1 \\
\end{pmatrix}_{t}}_{Z_{t}}

\underbrace{\begin{pmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{k+1}
\end{pmatrix}_{t-1}}_{x_{t-1}}

+


\underbrace{\begin{pmatrix}
v_{1} \\
v_{2} \\
\vdots \\
v_{k+1}
\end{pmatrix}_{t}}_{v_{t}}


\end{aligned}


## Dynamic regression with AR(1) coefficients

When a stationarity assumption is necessary on the parameters $\beta_{t}$ the
autoregressive process of order one represent the simplest form of dynamic linear model.


\begin{aligned}

y_{t} & = 

\underbrace{\begin{pmatrix}
1 & x_{1} & \cdots & x_{k}
\end{pmatrix}_{t}}_{B_{t}}

\underbrace{
\begin{pmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{k+1}
\end{pmatrix}_{t}}_{x_{t}}

+ w_{t}

\\

\underbrace{\begin{pmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{k+1}
\end{pmatrix}_{t}}_{x_{t}}


& = 

\underbrace{\begin{pmatrix}
\phi_{11} & 0 & \cdots & 0 \\
0 & \phi_{21} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \phi_{k1} \\
\end{pmatrix}_{t}}_{Z_{t}}

\underbrace{\begin{pmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{k+1}
\end{pmatrix}_{t-1}}_{x_{t-1}}

+


\underbrace{\begin{pmatrix}
v_{1} \\
v_{2} \\
\vdots \\
v_{k+1}
\end{pmatrix}_{t}}_{v_{t}}

\end{aligned}



# Dynamic Marketing Mix Model

## Data description

The data contains sales (expressed in thousand of units) and the corresponding advertising budget (expressed in thousand of dollars) for several media. The data ranges from 2001/01/01 to 2017/08/01 for a total of 200 observations.

## Preliminary Analysis

We begin by loading the packages used for the analysis

```{r, echo = TRUE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(MARSS)
library(corrplot)
library(patchwork)
library(reshape2)
```

```{r, echo = FALSE, warnings = FALSE, preview=TRUE}
# load the data
setwd("C:\\Users\\USR02193\\OneDrive - Chiesi Farmaceutici S.p.A\\Documents\\Marketing\\MMM")
advertising = read.csv("mediamix_sales.csv") 
advertising <- advertising %>% mutate(Time = as.Date(Time,"%d/%m/%y"))

```

After loading the data that in my case was on a desktop folder we begin the analysis
looking at the different time series.

```{r, echo = TRUE}
  advertising %>%
  select(-c("Native","Programmatic","OOH","sales")) %>% 
  pivot_longer(cols = -c("Time"), names_to = "Media") %>% 
  ggplot(aes(x = Time, y = value, color = Media, )) +
  geom_line() +
  facet_grid(rows  = vars(Media))+
  scale_x_date(date_breaks = "1 year",date_labels = "%Y") +
  theme(strip.background = element_blank(),
  strip.text = element_blank(), 
  axis.text.x = element_text(angle = 90)) +
  scale_y_continuous(breaks = seq(0, 250, by = 125))
```

A time series plot reveals that there is a great difference between the budget allocated to the different media. TV represents the media to which more money are allocated and the investments are divided depending on the TV program. Moreover, it emerges clearly that when some media are used other are stopped. In particular overt the period 2009-2011 no budget was allocated to Search and social media but a high investment was allocated to tv_cricket.

```{r}
advertising %>% select(-c("Time")) %>% cor() %>% corrplot()
```

From the correlation matrix it appears that sales are positively correlated with the budget allocated to TV, Radio, Social, Display rest and Search while there is no apparent linear relationship with the other media. TV and Radio represent the classical media more correlated with sales, while Social, Display_Rest and Search are the modern media with the highest correlation. As it is evident from the correlation matrix there is a strong positive correlation between the budget allocated to different media. For example there is an high positive correlation between Social, tv_sponsorship, Display_Rest and Search, meaning that when the budget in increased in one of these media is increased also in the others.


## Dynamic linear regression
```{r, echo  = TRUE}
# convert the data into a matrix
response <- matrix(advertising$sales, nrow = 1)

# covariates matrix (k x TT)
covariates <- advertising %>% select(-c("Time","sales"))
covariates <- t(covariates) 

# number of state = # of regression params (slope(s) + intercept)
m <- 1 + 12

# obtain the total number or observations
TT <- length(response)
```

Next, we proceed to specify the matrices needed for fitting the dlm model

```{r, echo = TRUE}
# STATE EQUATION
# specify the B matrix 
B <- diag(m)
# specify B matrix for AR1 states
diag(B)[2:13] <- paste("b",2:13, sep = "")
# specify remaining matrices
U <- matrix(0, nrow = m, ncol = 1) 
Q <- "unconstrained"

# OBSERVATION EQUATION
Z <- array(NA, c(1, m, TT)) # NxMxT; empty for now
Z[1, 1, ] <- rep(1, TT) # Nx1; 1's for intercept
Z[1, 2:13, ] <- covariates # Nx1; regr variable
A <- matrix(0) # 1x1; scalar = 0
R <- matrix("r") # 1x1; scalar = r

# initialize thate vector
inits.list <- list(x0 = matrix(0, nrow = m))
# set parameters for optimizer
cntl.list <- list(minit = 200, maxit = 20000)

# list of model matrices & vectors
mod.list <- list(B = B, U = U, Q = Q, Z = Z, A = A, R = R)
```

And finally we fit the model.

```{r, echo = TRUE, warnings = FALSE, message=FALSE}
# dlm with autoregressive states
dlr <- MARSS(response, inits = inits.list, model = mod.list,
                 control = cntl.list, silent = TRUE)
```


### Model analysis
We start by examining the smoothed states in Figure \@ref(fig:smoothstate).

```{r smoothstate, fig.cap= "Smoothed states"}
# obtain smoothed states
s<- tsSmooth(dlr)
colnames(s) <- c("state", "Year", "val","se")
state.names <- c("intercept",colnames(advertising)[2:m])
s$state <- rep(state.names,each = 200)

 s %>% ggplot() +
  geom_line(aes(x = Year, y = val,color = state), 
            size = 0.4, alpha = 0.7) +
  theme_minimal()+  
  ggtitle("States") +
  facet_wrap(~ state,ncol = 4, scales = 'free')

```
Looking at the smoothed states it appears that there is an high variation in the states.
The intercept, which represent the average volume of sales in absence of advertising 
activities in sales shows an increasing trend.
Display_Rest, Native, OOH, Programmatic Radio and Magazines shows an increasing marginal 
effect on the quantity of units sold. Programmatic being the one with the highest marginal
effect. The interpretation of the estimated negative values associated to the budget
allocated to a particular media has many interpretations. It might indicate that
for that period the particular activity performed on that media was not appreciated 
by the customer, or again  it might indicate that the customer got bored or not interested in that media and
using it as advertisement produced the opposite effect on sales.

```{r}
s %>% dcast(Year~state) %>% 
  select(-c("Year")) %>% cor() %>% 
  corrplot()
```

The correlation structure of the states is of complex interpretation. However 
the important thing is that it highlights the fact that there exhists synergies between
some medias. For example when the marginal effect of the budget allocated to
tv_sponsorship increases we expect that also the marginal effect allocated to
budget will increase.
Apart from the theoretical assumptions on the regression parameters one of the main
advantages in adopting a state space representation is the possibility of producing
forecasts as soon as new data is available. By running the Kalman filter, it is in
fact possible to produce the one step ahead forecasts, $\hat{y}_{t+1|t}$, in an 
iterative fashion. The one step ahead predictions obtained with the
fitted dynamic linear regression are reported in Figure \@ref(fig:yhat).

```{r yhat, fig.cap = "One ste ahead predictions"}
t <- advertising$Time
yhat <- forecast.marssMLE(dlr, type = "ytt1")$pred
colnames(yhat)[2:9] <- c("Time","sales", "predicted_sales", "se", "lo", "hi",
                         "LO", "HI")

yhat <- yhat[1:200,]
yhat$Time <- t


p1 <- yhat %>% ggplot() +
  geom_point(aes(x = Time, y = sales), color = "royalblue", 
            size = 1, alpha = 0.7) +
  geom_line(aes(x = Time, y = predicted_sales), color = "orange", 
            size = 0.8, alpha = 0.7) +
  geom_point(aes(x = Time, y = predicted_sales), color = "orange", 
            size = 1, alpha = 0.7) +
  theme_minimal()+  ggtitle("States")

```
### Model diagnostic
We conclude the analysis by inspecting the residuals plot, in order to identify 
violation to the underlying model assumptions

```{r, echo = FALSE, warning = FALSE, message=FALSE}
# extract model residuals
mod.res = autoplot(dlr, plot.type = "model.resids")$data 
mod.res$Time <- t
# extract state residuals
state.res <- autoplot(dlr, plot.type = "state.resids")$data
state.res$Time <- rep(t[2:length(t)], 13) 
```


```{r fittedres, fig.cap = "Fitted residuals", code_folding = TRUE}
# plot model residuals
 mod.res %>% ggplot() +
  geom_point(aes(x = Time, y = .resids), color = "royalblue", alpha = 0.4) +
  ylab("residuals") + ggtitle("Fitted residuals") +
  theme_minimal() 

```


```{r stateres, echo = FALSE, fig.cap = "State residuals", code_foldin = TRUE}
state.res %>% ggplot() +
  geom_point(aes(x = Time, y = .resids), color = "royalblue", alpha = 0.4) +
  geom_ribbon(aes(x = Time, ymin = - 1.96*.sigma, 
                  ymax = +1.96*.sigma), alpha = 0.3) +
  facet_wrap(~.rownames, ncol =4, scales = "free") +
  theme_minimal() +
  ylab("residuals") + ggtitle("State residuals")
```

Both the model and the state residuals appear to be well dispersed with no 
particular patterns that may indicate autocorrelation or cyclical behavior.
Both in the model and in the state residuals plot some outliers can be identified.

```{r}
mod.res %>% ggplot() +
  geom_qq(aes(sample = .resids), color = "royalblue", alpha = 0.4) +
  stat_qq_line(aes(sample = .resids), color = "red", alpha = 0.4) +
  theme_minimal() + 
  ggtitle("Model residuals")
```


```{r}
state.res %>% ggplot() +
  geom_qq(aes(sample = .resids, group = .rownames), color = "royalblue", alpha = 0.4) +
  stat_qq_line(aes(sample = .resids, group = .rownames), color = "red", alpha = 0.4) +
  facet_wrap(~.rownames, ncol = 4) +
  theme_minimal() + 
  ggtitle("State residuals")
```



Finally, the inspection of the qqplots reveal that there is no clear departure
from normality in the state while the model residuals appear to have heavier tails than
a normal distribution.