---
title: "Applying Dynamic Linear Regression to Marketing Mix Modelling"
description: ""
author:
  - first_name: Alessandro
  - second_name: Ghiretti
    url: https://example.com/
    affiliation: 
    affiliation_url: https://example.com/StateSpaceMarketingMix
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
      toc: true
      toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(dlm)
library(GGally)
```

# Introduction
Marketing mix modeling is a statistical analysis that links
multiple variables, including marketing, sales activities,
operations and external factors, to changes in consumer
behavior, such as acquisition, sales, revenue, and
retention. It can then support the development of forwardlooking business 
simulations and optimization exercises. When only advertising investement is considered
marketing mix modeling is generally called media mix modeling.

One of the models more used in practice for makreting and media mix modeling is the linear regression model. Once the regression is fitted and estimates are obtained for the unknown parameter, it is possible
to infer the effect that the regressors have on the response variable and obtain key informations such as marginal estimated contributions and elasticities.

Despite linear regression represent a model commonly adopted in practice because of its flexibility and simplicity, it is important to remark that when dealing with time series data several details must to 
be kept in mind when constructing the model. For example spurious correlations between predictors and the response, correlation structure in the errors terms, structural breaks, seasonality and so on.

One of the key assumptions about the plain linear regression model is that the estimates of the parameters remain constant over the period considered. This assumption appears to be limited in many context, for example in marketing it might be assumed that the marginal effect on budget allocated to different media changes, as the customer behavior or the penetration of one media evolves over time.

In order to overcome this last limitation the Dynamic Linear Regression Model, which allows for time varying parameters can be adopted. Once the DLM is casted in State Space form it is possible to estimate the parametersm in a dynamic way. 

We will first give an introduction to the State Space models, and then we will show, using the R package dlm, how to fit a DLM to a Media Mix Modeling problem.




# State Space Models
State space models provide a unified methodology for treating a wide range
of problems in time series analysis. In this approach it is assumed that the
development of the time series under study is determined by an unobserved component  $\alpha_{1},\dots,\alpha_{n}$, with which are associated a series of observations
$y_{1},\dots,y_{n}$; the relation between the $\alpha_{t}$’s and the $y_{t}$’s is specified by the state
space model. 
The main purpose of state space analysis is to infer the relevant
properties of the $\alpha_{t}$'s from a knowledge of the observations $y_{1},\dots,y_{n}$.
The simple linear gassian state space model is givne by

$$
\begin{aligned}
y_{t} &=Z_{t} \alpha_{t}+\varepsilon_{t}, & & \varepsilon_{t} \sim \mathrm{N}\left(0, H_{t}\right) \\
\alpha_{t+1} &=T_{t} \alpha_{t}+R_{t} \eta_{t}, & & \eta_{t} \sim \mathrm{N}\left(0, Q_{t}\right), & t=1, \ldots, n,
\end{aligned}
$$
where $y_{t}$ is a $p \times 1$ vector of observations called the observation vector and $\alpha_{t}$
is an unobserved $m \times 1$ vector called the state vector. The idea underlying the
model is that the development of the system over time is determined by $\alpha_{t}$
according to the second equation of, but because $\alpha_{t}$ cannot be observed
directly we must base the analysis on observations $y_{t}$. The first equation of 
is called the **observation equation** and the second is called the **state equation**. The
matrices $Z_{t}, T_{t}, R_{t}, H_{t} and Q_{t}$ are initially assumed to be known and the error
erms $\epsilon_{t}$ and $\eta_{t}$t are assumed to be serially independent and independent of each
other at all time points. 
In practice, some or all of the matrices $Z_{t}, T_{t}, R_{t}, H_{t} and Q_{t}$ will depend
on elements of an unknown parameter vector $psi$ that needs to be estimated.
Estimation of $\psi$ is generally performed by maximising the prediction error 
decomposition form of the likelihood 


$$
\log L\left(Y_{n}\right)=-\frac{n p}{2} \log 2 \pi-\frac{1}{2} \sum_{t=1}^{n}\left(\log \left|F_{t}\right|+v_{t}^{\prime} F_{t}^{-1} v_{t}\right)
$$

In order to obtain the prediction error decomposition of the likelihood the Kalman Filter is used.
The Kalman Filter consists of the following set of recursive equations.

$$
\begin{aligned}
v_{t} &=y_{t}-Z_{t} a_{t}, & F_{t} &=Z_{t} P_{t} Z_{t}^{\prime}+H_{t} \\
a_{t \mid t} &=a_{t}+P_{t} Z_{t}^{\prime} F_{t}^{-1} v_{t}, & P_{t \mid t} &=P_{t}-P_{t} Z_{t}^{\prime} F_{t}^{-1} Z_{t} P_{t} \\
a_{t+1} &=T_{t} a_{t}+K_{t} v_{t}, & P_{t+1} &=T_{t} P_{t}\left(T_{t}-K_{t} Z_{t}\right)^{\prime}+R_{t} Q_{t} R_{t}^{\prime}
\end{aligned}
$$

The application of the Kalman filter requires that the inizial condition of the systems $\alpha_{1} \sim N(a_{1},P_{1})$ are known. This rarely happens in practice and when the initial conditions of the system are not known the diffuse intiialization is adopted. In practice the diffuse inizialization consists in initializig the distribution of $\alpha_{1}$ with a high variance. When the diffuse initialization is adopted the resulting likelihood is

$$
\log L_{d}\left(Y_{n}\right)=-\frac{n p}{2} \log 2 \pi-\frac{1}{2} \sum_{t=1}^{d} w_{t}-\frac{1}{2} \sum_{t=d+1}^{n}\left(\log \left|F_{t}\right|+v_{t}^{\prime} F_{t}^{-1} v_{t}\right)
$$

where $w_{t}$ is a variable related to the.

## Regression with time varying parameters
State Space form represent a natural way to represent a linear regression with time varying parameters
. The observation equation is formulated as

$$ y_{t} = x'_{t}\beta_{t} + \epsilon_{t} \quad \epsilon_{t} \sim N(0,\sigma^{2})$$

where $y_{t}$ is the response variable observed at time $t$, $x_{t}$ is a $k \times 1$ vector of regressors, 
$\beta_{t}'$ is a $k \times 1$ vector of time varying parameters and $\epsilon_{t}$ is the error term.

In order to describe the behavior of the parameters the a state equation must be specified.
If the parameters $\beta_{t}$ are assumed follow a random walk model the full specification of the DLM becomes

$$
\begin{aligned}
y_{t} &= x'_{t} \beta_{t}+\varepsilon_{t} & & \varepsilon_{t} \sim \mathrm{N}\left(0, \sigma^{2}_{t}\right) \\
\beta_{t+1} &= \beta_{t}+\eta_{t} & & \eta_{t} \sim \mathrm{N}\left(0, Q_{t} \right) & t=1, \ldots, n,
\end{aligned}
$$
where $T_{t} = I$ and $Z_{t} = x'_{t}$. The behavior of the parameters is guided by the matrix $Q$, when $Q = 0$ the model reduces the standard static linear regression model.
Depending on the underlying assumptions or evidence other stochastic processes can be used to model the bahvior of the parameters $\beta_{t}$.
For example when cyclical behavior is observed an autoregressive process of order 2, can be used to model the parameters.That is,

$$ 
\begin{aligned}
y_{t} &= x'_{t} \beta_{t}+\varepsilon_{t}  \quad &\varepsilon_{t} \sim \mathrm{N}\left(0, \sigma^{2}_{t}\right) \\
\beta_{t+1} &= \phi_{0} + \phi_{1}\beta_{t-1} + \phi_{2} \beta_{t-2} + \eta_{t} \quad &\eta_{t} \sim N(0,Q). 
\end{aligned}
$$


The specification of the dynamic behavior of the parameters is generally guided by underlying assumptions or empirical evidence of the phenomena under study.

# Dynamic Marketing Mix Model

## Data description
The data contains sales (expressed in thousand of units) and the corresponding advertising budget (expressed in thousand of dollars) for TV, Radio and Newspaper. The data ranges from 2000/01/01 to 2016/08/01 for a total of 200 observations.

## Preliminary Analysis

```{r, echo = FALSE, warnings = FALSE}
# load the data
setwd("C:\\Users\\USR02193\\OneDrive - Chiesi Farmaceutici S.p.A\\Documents\\Marketing\\MMM")
advertising = read.csv("Advertising.csv") 
  
  # create dates
t = seq(as.Date("2000/01/01"), by = "month", length.out= 200)
  
  # Drop X variable
advertising <- advertising %>% mutate(t = t) %>% dplyr::select(-X) 
```
```{r, echo = FALSE, preview = TRUE}
advertising %>% pivot_longer(cols = -c("t"), names_to = "Media") %>% 
  ggplot(aes(x = t, y = value, color = Media)) +
  geom_line()
```
A time series plot reveals that there is a great difference between the budget allocated to the different channels. TV represents the media to which more money are allocated, followed by Newspaper and Radio.
With scatterplot matrix we inspect the relationship between the budget allocated to the different channels and the volume of sales.

```{r, echo = FALSE}
advertising  %>% select (-c("t")) %>% ggpairs()

```

It appears that there is an high correlation between sales and the investment in TV advertising, with a correlation coefficient of 0.782. The correlation with the other two media
, Radio and Newspaper is lower, with correlation coefficients of 0.576, 0.228.
Furthermore, the scatterplot of the sales with the TV and Radio budget shows heteroskedasticity in the data.
Despite the lack of a strong linear relationship both with Radio and Newspaper and the presence of non constant variance we proceed with our model specification.


## Media mix model specification 
A general model specification for media mix modeling is the standard linear regression model,

$$ y_{t} = \mu_{t} + \gamma_{t} + x_{t}'\beta + \epsilon_{t} \quad \epsilon_{t} \sim N(0,\sigma^{2}) $$

where $\mu_{t}$ is the trend component representing the long run beahvior of the series, $\gamma_{t}$ is the seasonal component, $x'_{t}$ is the vector of covariates, $\beta$ is the vector of unknown parameter and $\epsilon_{t}$ is the error term. When no seasonal behavior or trend are detected or assumed in the series the model reduces to

$$ y_{t}  = x'_{t}\beta + \epsilon_{t} \quad \epsilon_{t} \sim N(0,\sigma^{2}).$$

As stated in the introduction one limitation of the plain linear regression model is that the marginal effects of the explanatory variables, represented by $\beta$, remains constant over time. Nevertheless, in some context, it might be more natural to allow the vector $\beta$ to evolve with time.
In this example we will consider the following model

$$
\begin{aligned}
y_{t} &= x_{t}'\beta_{t} + \epsilon_{t} \quad &\epsilon_{t} \sim N(0,\sigma^{2}) \\
\beta_{t+1} &= \phi_{0} + \phi_{1}\beta_{t-1} + \eta_{t}  \quad &\eta_{t} \sim N(0, Q)
\end{aligned}
$$

where the behavior of the parameters is modeled as a random walk process.

## Fitting the model with dlm

The package that we will use to fit the dynamic linear model is dlm, developed by Giovanni Petris. The package provides a flexible environment for fitting Dynamic Linear Gaussian models.
Before to be fitted the data needs to be transformed into a ts object. Since the data are monthly we
set frequency equal to 12.

```{r, echo =TRUE}
# convert the data to a ts object
adv.ts <- ts(advertising, start = advertising$t[1], frequency = 12)
```

Next, we extract the response variable (sales) and the explanatory variables, and proceed to fit the model and obtain the filtered and the smoothed states.

```{r,echo = TRUE}
x <-  adv.ts[,1:3]
y <-  adv.ts[,4] 

# Define the linear regression model
# Logaritmic transofrmation is applied to variance components to increase
# the stability of the Kalman Filter
buildTVREG <-  function(parm, x.mat){
  # parametrize the model as log(variance)
  parm <- exp(parm)
  # return function output
  return(dlmModReg(X = x.mat, dV = parm[1], dW = parm[2:5]))
}

# Set initial values for optimizer
start.values = rep(0,5)
names(start.values) = c("lns2V","lns2a", "lns2TV", "lns2Radio", "lns2Newspaper")

# Obtaiun maximum likelihood estimates
TVREG.mle = dlmMLE(y = y, parm = start.values, x.mat = x, buildTVREG)
```



After having obtained the estimates of the parameters we check that the convergence criterion was met

```{r, echo =TRUE}
TVREG.mle$convergence
```
A zero values represent that the optimizer converged. The resulting estimated variances are

```{r, echo = FALSE}
exp(TVREG.mle$par)

```
The estimated variances can be built into the model to calculate the filtered and the smoothed states, which in our SS formulation correspond to the unknown parameters.

```{r, echo = TRUE}
# Assign parameters to the estimated model
TVREG.dlm <- buildTVREG(TVREG.mle$par,x)

# Obtain fitlered states
TVREG.f <- dlmFilter(y,TVREG.dlm)

# Obtain smoothed states
TVREG.s <-  dlmSmooth(TVREG.f)
```


Once the smoothed states are calculated we can plot them over the period considered.

```{r state-plot, echo = TRUE}
# Etract smoothed states
s = TVREG.s$s

# Assign column names to the smoothed states
colnames(s) <- c("State_Intercept","State_TV","State_Radio","State_Newspaper")

# Plot the smoothed states
s  %>% as_tibble() %>% 
  filter(between(row_number(),1,n()-1)) %>% 
  mutate(t = t) %>% 
  pivot_longer(cols = -c("t"), names_to = "pars") %>% 
  ggplot(aes (x = t, y = value, color = pars)) +
  geom_line() +
  ylab("Smoothed State") +
  facet_wrap(.~pars, scales = "free")
```

The smoothed intercept represent the expected volume of sales when no budget is allocated in media investment while the other states represent the unitary increase in volume of sales when another dollar is allocated to the corresponding media channel.
Plot \@ref(fig:state-plot) shows all the smoothed states over the period considered.
From 2001 to 2005 the intercept shows an light upward trend followed by a marked negative trend and a slight recovery during the last months.
The parameter of the newspaper shows a marked positive trend. Importantly it switches from a negative to a positive sign. Meaning that while at the beginning of the period considered investing in newspaper had a negative effect on sales now it has a positive effect. The marginal effect of Radio shows an unstable behavior with a marked drop after 2010 followed by a rapid increase.
Finally, the marginal effect of the TV budget shows a steady negative trend meaning that the effect of TV advertising is decreasing.

## Elasticities
The estimated model is given by

$$ 
\widehat{sales}_{t}  = \hat{\beta}_{0t} +  TV_{t} \times \hat{\beta}_{1t} + Radio_{t} \times  \hat{\beta}_{2t} + Newspaper_{t} \times \hat{\beta}_{3t}  
$$

where each $\beta_{t}$ is modeled as a random walk process. The elasticity can next be obtained as

$$
E_{jt} = \frac{\Delta y}{\Delta x} \cdot \frac{x}{y} = \beta_{jt} \frac{x}{y}.
$$

To calculate the elasticities we substitute for $x$ and $y$ their means. Another common approach to estimate elasticities with regression models is to adopt a double log transformation, which result in a model of the form

$$
log(y_{t}) = log(x'_{t})\beta + \epsilon_{t}
$$
Under this transformation the estimated parameter $\hat{\beta}$ correspond to the value of the elasticity.

The resulting elasticties obtained from the smoothed states are shown in figure ()


```{r, include = TRUE, echo =TRUE}
# Obtain the elasticities from the smoothed states
elasticities <- s %>% as_tibble() %>%
  filter(between(row_number(),1,n()-1)) %>% 
  cbind(advertising) %>% 
  mutate(TV_el = State_TV*(mean(TV)/mean(Sales)),
         Radio_el = State_Radio*(mean(Radio)/mean(Sales)),
         Newspaper_el = State_Newspaper*(mean(Newspaper)/mean(Sales))) %>%
  select(t,contains("el")) %>% 
  rename("TV" = "TV_el", "Radio" = "Radio_el", "Newspaper" = "Newspaper_el")
           
# Plot the elasticities
elasticities %>% 
  pivot_longer(cols = -c("t"), names_to = "Elasticities") %>% 
  ggplot(aes (x = t, y = abs(value), color = Elasticities)) +
  geom_line() +
  ylab("Elasticities") +
  facet_grid(rows = vars(Elasticities), scales = "free")
```

From the plot it appears that the volume of sales is unelastic to all the medias considered in the model.
TV represent the channel with the higher elasticity, however as it show in the plot the elasticity exhibits a decreasing behavior.
The elasticities associated to Radio and Newspaper despite being lower compared to the TV have show a marked upward trend, meaning that in the future these media might represent the best channels to which allocate budget to increase sales. 


Finally we can forecast the future states for the next twelve months and calculate the corresponding elasticities.


```{r include = TRUE}
# Add 12 months as NA at the end of the sample period
y.hat <- rep(NA,12) %>% ts(start = as.Date(seq(from=last(t), by="months", length.out=12)),
                           frequency = 12)

# Combined time series object
y.new <- ts(c(y, y.hat), start = start(y), frequency = frequency(y))

# Obtain predicted states
TVREG.hat = dlmFilter(y.new, TVREG.dlm)

# Extract estimated states
TVREG.hat$m[201:212,]

```

Having modeled the states as random walk does not provide much predictive power. With more structure imposed on the states such as a random walk with drift or an autoregressive process better informative forecasts can in principle be obtained.

## Conclusions
In this example we showed how state space models can be used to augment the information provided by static time series models. The state space formulation is general and can be adopted for many different models. With it and the Kalman Filter smoothing, filtering and predicting can be performed.  In this particular example the analysis of the smoothed states in the Dynamic Linear Regression  showed how the marginal effect of the different media changed over the period considered. It is important to note that the behavior of the estimated parameters might also be a symptom of mispecification. In fact, as more variable are added to the model or a different specification is suggested the smoothed states might result in constant values. Moreover, in this particular case the estimated variances resulted particularly small and the variation observed in the smoothed state could be negligible for practical purposes.


