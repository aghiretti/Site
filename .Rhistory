install.packages("paradox")
rm(list = ls())
install.packages(paradox)
install.packages("paradox")
install.packages("paradox")
knitr::opts_chunk$set(echo = TRUE)
library(paradox)
library(paradox)
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally)
library(reshape2)
library(mlr3verse)
library(mlr3extralearners)
library(mlr3pipelines)
library(cattonum)
setwd("C:\\Users\\USR02193\\OneDrive - Chiesi Farmaceutici S.p.A\\Desktop\\Blog\\Data\\PPC\\")
# load train and test data
train <- read.csv("train.csv")
test <- read.csv("test.csv")
# number of advertisers
n_adv <- length(unique(train$advertiser_id))
n_usr <- length(unique(train$user_id))
n_kyw <- length(unique(train$keyword_id))
######################## METRICS ######################
# 1) ad metrics
ad_metrics <- train %>% group_by(ad_id) %>%
summarise(
n_clicks = sum(click),
tot_clicks = length(click),
prc_clicks = (sum(click)/length(click))*100) %>%
arrange(desc(n_clicks))
# 2) advertiser metrics
adv_metrics <- train %>% group_by(advertiser_id) %>%
summarise(
n_clicks = sum(click),
tot_clicks = length(click),
prc_clicks = (sum(click)/length(click))*100) %>%
arrange(desc(n_clicks))
# 3) keyword metrics
adv_keyword <- train %>% group_by(keyword_id) %>%
summarise(
n_clicks = sum(click),
tot_clicks = length(click),
prc_clicks = (sum(click)/length(click))*100) %>%
arrange(desc(n_clicks))
train %>% select(click) %>% melt() %>% ggplot()+
geom_bar(aes(x = value, fill = factor(value)), alpha = 0.7) + theme_minimal()
sum(train$click)
sum(train$click)
sum(!train$click)
(sum(train$click)/nrow(train))*100
print(apply(train,2, function(x) length(unique(x))))
# define the classification task
train$click <- factor(train$click)
task <- TaskClassif$new(id = "ppc", train, target = "click")
# define learners and ids
learners <- c("classif.ksvm", "classif.kknn", "classif.xgboost")
# obtain the selected learners
learners <- lapply(learners,lrn)
# define balancing pipeline
po_under <- po("classbalancing", id = "undersample", adjust = "minor",
reference = "minor", shuffle = FALSE, ratio = 1 / 6)
po_over <- po("classbalancing", id = "oversample", adjust = "major",
reference  = "major", shuffle = FALSE, ratio = 6)
# define the sampling strategy
inner_resampler <- rsmp("cv", folds = 10L)
# define the outer resampler
outer_resampler <- rsmp("cv", folds = 5L)
# define the tuner
tuner <- tnr("random_search")
learners[[1]]
learners[[1]]$param_set
library(dplyr)
library(tidyr)
library(ggplot2)
library(MARSS)
library(formattable)
library(patchwork)
library(plotly)
library(reshape)
library(RColorBrewer)
# Read data
co2 <- read.csv("owid-co2-data.csv")
# Filter countries to include in the analysis
countries <- c("Italy","United Kingdom","France","Germany","Spain","United States",
"Canada","Japan", "India", "China",  "Argentina",
"Brazil", "Peru", "New Zealand", "Australia")
# Define geographical zones
zone <- c(rep("Europe",5), rep("North America", 2), rep("Asia",2),
rep("South America",3), rep("Oceania",2))
# Add geographical zones to the data
co2 <-co2 %>%
mutate(zone = ifelse(country %in%
c("Italy","United Kingdom","France","Germany","Spain"),
"Europe",ifelse( country %in% c ("United States","Canada"), "North America",
ifelse(country %in% c("Japan", "India", "China"), "Asia",
ifelse(country %in% c("Argentina","Brazil", "Peru"),"South America", "Oceania")))))
# Filter the data
dat <- co2 %>%
# filter the countries and the year
filter(country %in% countries &
year >= 1910)
nb.cols <- length(countries)
mycolor <- mycolors <- colorRampPalette(brewer.pal(9, "YlGnBu"))(nb.cols)
# Co2 Emissions Plot
# Plot co2 emissions
p1 <- dat %>% ggplot(aes(x = year, y = share_global_co2, color = country)) +
geom_line() +
scale_color_manual(values = mycolor) +
ggtitle("CO2 world share")+
ylab("CO2 share") +
theme_minimal()
ggplotly(p1)
p1 <- dat %>% ggplot(aes(x = year, y = log(share_global_co2), color = country)) +
geom_line() +
scale_color_manual(values = mycolor) +
ggtitle("log(CO2) worldwide share")+
ylab("log(CO2) share") +
theme_minimal()
ggplotly(p1)
p1 <- dat %>% ggplot(aes(x = year, y = co2_per_capita, color = country)) +
geom_line() +
scale_color_manual(values = mycolor) +
ggtitle("Global share of CO2")+
ylab("CO2 share") +
theme_minimal()
ggplotly(p1)
p1 <- dat %>% ggplot(aes(x = zone, y = co2_per_capita, color = country)) +
geom_boxplot() +
scale_color_manual(values = mycolor) +
ggtitle("CO2 per capita boxplot")+
ylab("CO2 per capita") +
theme_minimal()
p1
p1 <- dat %>%
group_by(year,zone) %>% summarise(co2 = sum(co2_per_capita)) %>%
ggplot() +
geom_line(aes(x = year, y = co2, color = zone),
size = 1.2, alpha = 0.6) +
scale_color_brewer(palette = "Set2") +
ggtitle("CO2 per capita at continet level")+
ylab("CO2 per capita") +
theme_minimal()
ggplotly(p1)
dat %>% ggplot(aes(x = zone, y = co2_per_capita, color = country)) +
geom_qq_line()
dat %>% ggplot() +
geom_qq_line(aes(sample = co2_per_capita, color = country))
dat %>% ggplot() +
geom_qq_line(aes(sample = co2_per_capita, color = country)) +
dat %>% ggplot() +
geom_qq(aes(sample = co2_per_capita, color = country)) +
stat_qq_line(aes(sample = co2_per_capita, color = country))
library(dplyr)
library(tidyr)
library(ggplot2)
library(MARSS)
library(formattable)
library(patchwork)
library(plotly)
library(reshape)
library(RColorBrewer)
# Read data
co2 <- read.csv("owid-co2-data.csv")
# Filter countries to include in the analysis
countries <- c("Italy","United Kingdom","France","Germany","Spain","United States",
"Canada","Japan", "India", "China",  "Argentina",
"Brazil", "Peru", "New Zealand", "Australia")
# Define geographical zones
zone <- c(rep("Europe",5), rep("North America", 2), rep("Asia",2),
rep("South America",3), rep("Oceania",2))
# Add geographical zones to the data
co2 <-co2 %>%
mutate(zone = ifelse(country %in%
c("Italy","United Kingdom","France","Germany","Spain"),
"Europe",ifelse( country %in% c ("United States","Canada"), "North America",
ifelse(country %in% c("Japan", "India", "China"), "Asia",
ifelse(country %in% c("Argentina","Brazil", "Peru"),"South America", "Oceania")))))
# Filter the data
dat <- co2 %>%
# filter the countries and the year
filter(country %in% countries &
year >= 1910)
nb.cols <- length(countries)
mycolor <- mycolors <- colorRampPalette(brewer.pal(9, "YlGnBu"))(nb.cols)
# Co2 Emissions Plot
# Plot co2 emissions
p1 <- dat %>% ggplot(aes(x = year, y = share_global_co2, color = country)) +
geom_line() +
scale_color_manual(values = mycolor) +
ggtitle("CO2 world share")+
ylab("CO2 share") +
theme_minimal()
ggplotly(p1)
p1 <- dat %>% ggplot(aes(x = year, y = log(share_global_co2), color = country)) +
geom_line() +
scale_color_manual(values = mycolor) +
ggtitle("log(CO2) worldwide share")+
ylab("log(CO2) share") +
theme_minimal()
ggplotly(p1)
p1 <- dat %>% ggplot(aes(x = year, y = co2_per_capita, color = country)) +
geom_line() +
scale_color_manual(values = mycolor) +
ggtitle("Global share of CO2")+
ylab("CO2 share") +
theme_minimal()
ggplotly(p1)
p1 <- dat %>% ggplot(aes(x = zone, y = co2_per_capita, color = country)) +
geom_boxplot() +
scale_color_manual(values = mycolor) +
ggtitle("CO2 per capita boxplot")+
ylab("CO2 per capita") +
theme_minimal()
p1
p1 <- dat %>%
group_by(year,zone) %>% summarise(co2 = sum(co2_per_capita)) %>%
ggplot() +
geom_line(aes(x = year, y = co2, color = zone),
size = 1.2, alpha = 0.6) +
scale_color_brewer(palette = "Set2") +
ggtitle("CO2 per capita at continet level")+
ylab("CO2 per capita") +
theme_minimal()
ggplotly(p1)
m <- dat %>%
select(country,year,co2_per_capita) %>%
pivot_wider( names_from  = country, values_from = co2_per_capita) %>%
select(-c("year")) %>%
cor() %>% melt()
ggplot(m, aes(x = X1, y = X2, fill = value), alpha = 0.4) +
geom_tile() +
scale_fill_gradient(low = "pink", high = "royalblue")+
xlab("") + ylab("") +
theme_minimal()+  theme( panel.background = element_blank(),
axis.text.x = element_text(size = 7, angle = 90))
# row: country column: year
y <- dat %>%
select(co2_per_capita, year, country, iso_code) %>%
pivot_wider(names_from = year, values_from = co2_per_capita) %>%
arrange(iso_code)
# convert the data in matrix
y = as.matrix(y[,3:ncol(y)])
# set parameters for optimizer
cntl.list <- list(minit = 200, maxit = 5000, allow.degen = FALSE)
#  Define values for grid search
# define covariance structures for the states
R.structure <- "unconstrained"
m <- 3
model.list <- list(m = m, R = R.structure)
# fit model to standardized data
mod.me <- MARSS(y, model = model.list, z.score = TRUE, form = "dfa",
control = cntl.list, silent = TRUE)
# perform rotation of the states before plotting
# get the inverse of the rotation matrix
Z.est <- coef(mod.me, type = "matrix")$Z
H.inv <- 1
if (ncol(Z.est) > 1){
H.inv <- varimax(coef(mod.me, type = "matrix")$Z)$rotmat}
# rotate factor loadings
Z.rot <- Z.est %*% H.inv
#extract the rotated loadings and reshape into a matrix
loadings <- t(Z.rot) %>% data.frame()
colnames(loadings) <- unique(dat$country)
loadings$x <- c("X1","X2", "X3")
# add zone to the loadings
loadings <- loadings %>%
pivot_longer(-c("x"), names_to = "country", values_to = "loading") %>%
mutate(zone = ifelse(country %in%
c("Italy","United Kingdom","France","Germany","Spain"),
"Europe",ifelse( country %in% c ("United States","Canada"), "North America",
ifelse(country %in% c("Japan", "India", "China"), "Asia",
ifelse(country %in% c("Argentina","Brazil", "Peru"),"South America", "Oceania")))))
# rotate trends and covnert them to a data frame
trends.rot <- solve(H.inv) %*% mod.me$states
trends.rot <- t(trends.rot)
trends.rot <- data.frame(trends.rot)
# assign column names
colnames(trends.rot) <- c("X1","X2","X3")
# add year and reshape
trends.rot$Year <- seq(from = 1910, to = 2018)
trends.rot <- trends.rot %>%
pivot_longer(cols = -c("Year"),
names_to = "state", values_to = "val") %>%
group_by(state) %>% dplyr::arrange(Year, .by_group = TRUE)
# obtain estimated states
s <- tsSmooth(mod.me)
colnames(s) <- c("state", "Year", "val","se")
s$statesRot <- trends.rot$state
s$Year <- rep(seq(from = 1910, to =2018),3)
p1 <- trends.rot %>% ggplot() +
geom_line(aes(x = Year, y = val, group = state, color = state), size = 1.3, alpha = 0.7) +
scale_color_brewer(palette = "Set2") +
theme_minimal()+
ggtitle("Smoothed states") +
facet_wrap(~ state ,ncol = 2)
p2 <- s %>% ggplot() +
geom_line(aes(x = Year, y = val, group = state, color = state), size = 1.3, alpha = 0.7) +
scale_color_brewer(palette = "Set2") +
theme_minimal()+
ggtitle("Rotated states") +
facet_wrap(~ state,ncol = 2)
p1/p2
# Loadings by country
m <- loadings %>%
arrange(desc(loading)) %>%
ggplot() +
geom_bar(stat = "identity", aes(x = country, y = loading,
fill = country, color = country)) +
scale_color_manual(values = mycolor) +
scale_fill_manual(values = mycolor) +
theme_minimal()+  theme(legend.position = "none", panel.background = element_blank(),
axis.text.x = element_text(size = 7, angle = 90))+
ylab("loadings")+
ggtitle("Factor loadings by country") +
xlab("")+
facet_wrap(~x,ncol = 2)
ggplotly(m)
y.hat <- predict(mod.me, type = "ytt1")$pred
y.hat <- y.hat %>%
# add columns
mutate(country = rep(unique(dat$country),each = nrow(y.hat)/15),
Year = rep(seq(from = 1910, to = 2018), 15))
p1 <- y.hat %>% ggplot() +
geom_point(aes(x = Year, y = y, group = country),color = "pink", alpha = 0.7) +
geom_line(aes(x = Year, y = estimate, group = country),
size = 1, color = "royalblue", alpha = 0.7) +
facet_wrap(~country, ncol = 3) +
ggtitle("One step ahead predictions") +
theme_minimal()
ggplotly(p1)
# define the metrics
mse <- function(x){
m <- mean((x$y - x$estimate)^2)
return(m)
}
mae <- function(x){
m <- mean(abs(x$y - x$estimate))
return(m)
}
mape <- function(x){
m <- mean(abs(((100*(x$y - x$estimate))/x$y)))
return(m)
}
# estimate the metrics for the different series
metrics <- y.hat %>% group_by(country) %>%
nest() %>% mutate(mse = lapply(data,mse),
mae = lapply(data,mae),
mape = lapply(data,mape)) %>%
unnest() %>%
dplyr::select(country,mse,mae,mape) %>%
arrange(desc(mse), desc(mae), desc(mape)) %>%
unique()
metrics %>% formattable(list(`mae` = color_bar("#FA614B"),
`mse` = color_bar("#FA614B"),
`mape` = color_bar("#FA614B")))
# extract model residuals
mod.res = autoplot(mod.me, plot.type = "model.resids")$data %>%
mutate(country = rep(unique(dat$country),each = nrow(y.hat)/15),
Year = rep(seq(from = 1910, to = 2018), 15))
# extract state residuals
state.res = autoplot(mod.me, plot.type = "state.resids")$data %>%
mutate(Year = rep(seq(from = 1911, to =2018),3))
# plot model residuals
p1 <- mod.res %>% ggplot() +
geom_point(aes(x = Year, y = .resids, group = country), color = "royalblue", alpha = 0.4) +
geom_ribbon(aes(x = Year, ymin = - 1.96*.sigma,
ymax = +1.96*.sigma), alpha = 0.4) +
facet_wrap(~country, ncol = 3) +
theme_minimal() +
ylab("residuals") + ggtitle("Fitted residuals")
ggplotly(p1)
p1 <- state.res %>% ggplot() +
geom_point(aes(x = Year, y = .resids, group = .rownames), color = "royalblue", alpha = 0.4) +
geom_ribbon(aes(x = Year, ymin = - 1.96*.sigma,
ymax = +1.96*.sigma), alpha = 0.3) +
facet_wrap(~.rownames, ncol = 2) +
theme_minimal() +
ylab("residuals") + ggtitle("State residuals")
ggplotly(p1)
p1 <- mod.res %>% ggplot() +
geom_qq(aes(sample = .resids, group = country), color = "royalblue", alpha = 0.4) +
stat_qq_line(aes(sample = .resids, group = country), color = "red", alpha = 0.4) +
facet_wrap(~country, ncol = 3) +
theme_minimal() +
ggtitle("State residuals")
ggplotly(p1)
mod.res
ggplot.corr <- function(data, lag.max = 24, ci = 0.95, large.sample.size = TRUE, horizontal = TRUE,...) {
require(ggplot2)
require(dplyr)
require(cowplot)
if(horizontal == TRUE) {numofrow <- 1} else {numofrow <- 2}
list.acf <- acf(data, lag.max = lag.max, type = "correlation", plot = FALSE)
N <- as.numeric(list.acf$n.used)
df1 <- data.frame(lag = list.acf$lag, acf = list.acf$acf)
df1$lag.acf <- dplyr::lag(df1$acf, default = 0)
df1$lag.acf[2] <- 0
df1$lag.acf.cumsum <- cumsum((df1$lag.acf)^2)
df1$acfstd <- sqrt(1/N * (1 + 2 * df1$lag.acf.cumsum))
df1$acfstd[1] <- 0
df1 <- select(df1, lag, acf, acfstd)
list.pacf <- acf(data, lag.max = lag.max, type = "partial", plot = FALSE)
df2 <- data.frame(lag = list.pacf$lag,pacf = list.pacf$acf)
df2$pacfstd <- sqrt(1/N)
if(large.sample.size == TRUE) {
plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
geom_area(aes(x = lag, y = qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
geom_col(fill = "#4373B6", width = 0.7) +
scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("ACF") +
theme_bw()
plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
geom_area(aes(x = lag, y = qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
geom_col(fill = "#4373B6", width = 0.7) +
scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("PACF") +
theme_bw()
}
else {
plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
geom_col(fill = "#4373B6", width = 0.7) +
geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("ACF") +
theme_bw()
plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
geom_col(fill = "#4373B6", width = 0.7) +
geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("PACF") +
theme_bw()
}
cowplot::plot_grid(plot.acf, plot.pacf, nrow = numofrow)
}
4
ggplot.corr(data =state.res$.resids, lag.max = 24, ci= 0.95, large.sample.size = TRUE, horizontal = TRUE)
plot(mod.me)
plot(mod.me)q
plot(mod.me)
y
nrow(y)
mod.me
autoplot(mod.me)
# plot model residuals
p1 <- mod.res %>% ggplot() +
geom_point(aes(x = Year, y = .resids, group = country), color = "royalblue", alpha = 0.4) +
geom_ribbon(aes(x = Year, ymin = - 1.96*.sigma,
ymax = +1.96*.sigma), alpha = 0.4) +
facet_wrap(~country, ncol = 3, scales = "free") +
theme_minimal() +
ylab("residuals") + ggtitle("Fitted residuals")
ggplotly(p1)
p1 <- mod.res %>% ggplot() +
geom_qq(aes(sample = .resids, group = country), color = "royalblue", alpha = 0.4) +
stat_qq_line(aes(sample = .resids, group = country), color = "red", alpha = 0.4) +
facet_wrap(~country, ncol = 3, scales = "free") +
theme_minimal() +
ggtitle("State residuals")
ggplotly(p1)
p1 <- state.res %>% ggplot() +
geom_qq(aes(sample = .resids, group = .rownames), color = "royalblue", alpha = 0.4) +
stat_qq_line(aes(sample = .resids, group = .rownames), color = "red", alpha = 0.4) +
facet_wrap(~.rownames, ncol = 2) +
theme_minimal() +
ggtitle("State residuals")
ggplotly(p1)
my_data <- read.delim("http://www.dougstats.com/20-21RD.txt")
head(my_data)
library(dplyr)
library(janitor)
library(tidyr)
colnames(my_data) <- janitor::clean_names(colnames(my_data))
?clean_names
colnames(my_data) <- janitor::clean_names(my_data)
head(my_data)
my_data <- read.delim("http://www.dougstats.com/20-21RD.txt")
colnames(my_)
colnames(my_data)
?read.delim
my_data <- read.delim("http://www.dougstats.com/20-21RD.txt", header = TRUE)
colnames(my_data)
my_data <- read.delim("C:\\\Users\\\USR02193\\OneDrive - Chiesi Farmaceutici S.p.A\\Desktop\\Blog\\Data\\Basket\\
20-21RD.csv", header = TRUE)
my_data <- read.delim("C:\\\Users\\\USR02193\\OneDrive - Chiesi Farmaceutici S.p.A\\Desktop\\Blog\\Data\\Basket\\20-21RD.csv", header = TRUE)
my_data <- read.delim("C:\\Users\\USR02193\\OneDrive - Chiesi Farmaceutici S.p.A\\Desktop\\Blog\\Data\\Basket\\20-21RD.csv", header = TRUE)
head(my_data)
colcolnames(my_data) <- janitor::clean_names(my_data)
colnames(my_data) <- janitor::clean_names(my_data)
head(my_data)
